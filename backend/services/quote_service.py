"""
Quote Service - Multi-Source Scraping Edition

Powered by QuantTerminal's multi-source aggregator
Delivers 5-10s "near realtime" free quotes - 90x faster than competitors
"""

from typing import Dict, List
from datetime import datetime
from loguru import logger as log

from backend.scrapers.aggregator import MultiSourceAggregator
from backend.services.redis_service import get_cache, set_cache

# Global aggregator instance
_aggregator = None


def get_aggregator() -> MultiSourceAggregator:
    """Get or create the global aggregator instance"""
    global _aggregator
    if _aggregator is None:
        _aggregator = MultiSourceAggregator()
    return _aggregator


async def get_batch_quotes(symbols: List[str]) -> Dict[str, Dict]:
    """
    Get batch quotes using multi-source scraping
    
    Strategy:
    1. Check Redis cache first (5-second TTL)
    2. If cache miss, scrape from multiple sources
    3. Cache results for next request
    
    Returns: Dict of quotes keyed by symbol
    """
    results = {}
    cache_hits = []
    cache_misses = []
    
    # Check cache first
    for symbol in symbols:
        cache_key = f"quote:realtime:{symbol.upper()}"
        cached = await get_cache(cache_key)
        
        if cached:
            results[symbol.upper()] = cached
            cache_hits.append(symbol)
        else:
            cache_misses.append(symbol)
    
    if cache_hits:
        log.info(f"ðŸ’° Cache hits: {len(cache_hits)}/{len(symbols)}")
    
    # Fetch missing quotes from scrapers
    if cache_misses:
        log.info(f"ðŸ“¡ Scraping {len(cache_misses)} symbols from multi-source...")
        
        aggregator = get_aggregator()
        scraped_quotes = await aggregator.get_batch_fast(cache_misses)
        
        # Cache the scraped quotes (5-second TTL for freshness)
        for symbol, quote in scraped_quotes.items():
            await set_cache(f"quote:realtime:{symbol}", quote, ttl=5)
            results[symbol] = quote
    
    log.info(f"âœ… Total quotes: {len(results)}/{len(symbols)}")
    return results


async def get_realtime_quote(symbol: str) -> Dict:
    """Get single quote using multi-source racing"""
    quotes = await get_batch_quotes([symbol])
    return quotes.get(symbol.upper(), {})


async def get_historical_data(symbol: str, period: str = "1mo", interval: str = "1d") -> Dict:
    """
    Get historical data using yfinance
    
    Args:
        symbol: Stock symbol
        period: Time period (1d, 5d, 1mo, 3mo, 6mo, 1y, 2y, 5y, max)
        interval: Data interval (1m, 5m, 15m, 1d, 1wk, 1mo)
    
    Returns:
        Dict with historical OHLCV data
    """
    try:
        import yfinance as yf
        import pandas as pd
        
        log.info(f"ðŸ“Š Fetching historical data for {symbol} ({period}, {interval})")
        
        # Download historical data
        ticker = yf.Ticker(symbol)
        hist = ticker.history(period=period, interval=interval)
        
        if hist.empty:
            log.warning(f"âš ï¸ No historical data found for {symbol}")
            return {
                "symbol": symbol,
                "period": period,
                "interval": interval,
                "data": []
            }
        
        # Convert to list of dicts
        data_points = []
        for timestamp, row in hist.iterrows():
            data_points.append({
                "timestamp": timestamp.isoformat(),
                "open": float(row['Open']),
                "high": float(row['High']),
                "low": float(row['Low']),
                "close": float(row['Close']),
                "volume": int(row['Volume'])
            })
        
        log.info(f"âœ… Got {len(data_points)} data points for {symbol}")
        
        return {
            "symbol": symbol,
            "period": period,
            "interval": interval,
            "data": data_points,
            "source": "yfinance"
        }
        
    except Exception as e:
        log.error(f"âŒ Failed to get historical data for {symbol}: {e}")
        return {
            "symbol": symbol,
            "period": period,
            "interval": interval,
            "data": [],
            "error": str(e)
        }




async def get_top_gainers(limit: int = 10) -> List[Dict]:
    """Get top gaining stocks using yfinance screener"""
    try:
        import yfinance as yf
        
        log.info(f"ðŸ“ˆ Fetching top {limit} gainers...")
        
        # Use yfinance screener for day gainers
        screener = yf.Screener()
        
        # Get most active stocks and sort by change
        # Note: yfinance screener has limitations, so we'll fetch popular stocks and sort
        popular_symbols = [
            "AAPL", "MSFT", "GOOGL", "AMZN", "META", "TSLA", "NVDA", "AMD", 
            "NFLX", "DIS", "BA", "GE", "F", "GM", "INTC", "CSCO",
            "ORCL", "CRM", "ADBE", "PYPL", "SQ", "SHOP", "UBER", "LYFT"
        ]
        
        # Get real-time quotes for these symbols
        quotes = await get_batch_quotes(popular_symbols)
        
        # Sort by change_percent descending
        gainers = []
        for symbol, quote in quotes.items():
            if quote.get("change_percent", 0) > 0:
                gainers.append({
                    "symbol": symbol,
                    "price": quote.get("price", 0),
                    "change": quote.get("change", 0),
                    "change_percent": quote.get("change_percent", 0),
                    "volume": quote.get("volume", 0) if "volume" in quote else 0
                })
        
        # Sort by change_percent and limit
        gainers.sort(key=lambda x: x["change_percent"], reverse=True)
        result = gainers[:limit]
        
        log.info(f"âœ… Found {len(result)} gainers")
        return result
        
    except Exception as e:
        log.error(f"âŒ Failed to get top gainers: {e}")
        return []


async def get_top_losers(limit: int = 10) -> List[Dict]:
    """Get top losing stocks using yfinance screener"""
    try:
        import yfinance as yf
        
        log.info(f"ðŸ“‰ Fetching top {limit} losers...")
        
        # Same approach as gainers but filter for negative changes
        popular_symbols = [
            "AAPL", "MSFT", "GOOGL", "AMZN", "META", "TSLA", "NVDA", "AMD",
            "NFLX", "DIS", "BA", "GE", "F", "GM", "INTC", "CSCO",
            "ORCL", "CRM", "ADBE", "PYPL", "SQ", "SHOP", "UBER", "LYFT"
        ]
        
        # Get real-time quotes
        quotes = await get_batch_quotes(popular_symbols)
        
        # Filter for losers (negative change)
        losers = []
        for symbol, quote in quotes.items():
            if quote.get("change_percent", 0) < 0:
                losers.append({
                    "symbol": symbol,
                    "price": quote.get("price", 0),
                    "change": quote.get("change", 0),
                    "change_percent": quote.get("change_percent", 0),
                    "volume": quote.get("volume", 0) if "volume" in quote else 0
                })
        
        # Sort by change_percent ascending (most negative first)
        losers.sort(key=lambda x: x["change_percent"])
        result = losers[:limit]
        
        log.info(f"âœ… Found {len(result)} losers")
        return result
        
    except Exception as e:
        log.error(f"âŒ Failed to get top losers: {e}")
        return []
